optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.000032,
  weight_decay : 0.0005
}}

scheduler: {
  type: LambdaLR,
  kwargs: {
  decay_step: 100,
  lr_decay: 0.2,
  lowest_decay: 0.1  # min lr = lowest_decay * lr
}}

bnmscheduler: {
  type: Lambda,
  kwargs: {
  decay_step: 50,
  bn_decay: 0.5,
  bn_momentum: 0.05625,
  lowest_decay: 0.01
}}

model : {
  NAME: EINet, num_pred: 8192, num_seeds: 512, dim_seed_fea: 128, dim_feat: 512, upscales: [1,2,4], scales: [0.4,0.3,0.2]}

loss : {
  sparse_loss_weight: 1.0,
  dense_loss_weight: 1.0,
  dz_weight: 1.0,
  orth_weight: 1.0,
}
total_bs : 64
step_per_update : 1
max_epoch : 550

consider_metric: CDL2